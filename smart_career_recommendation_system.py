# -*- coding: utf-8 -*-
"""Smart Career Recommendation System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ztDXOdEeCUkfaTBlhUS0JNBFVJKNKm7H
"""

import os
import pandas as pd
import io

# Create directories
os.makedirs('data/raw', exist_ok=True)

# Corrected raw data with quoted fields containing commas
raw_data_corrected = """title,company,location,description,requirements,posted_date
Data Scientist,Acme Corp,Remote,"We are looking for a Data Scientist with experience in machine learning and python.","Must know pandas, scikit-learn, sql",2024-07-01
Backend Engineer,Techify,New York,"Backend engineer to build scalable APIs using java and node.js.","Experience with java, docker, aws",2024-06-15
Frontend Developer,WebWorks,San Francisco,"Frontend developer skilled in react and javascript.","React, javascript, css, html",2024-08-01
DevOps Engineer,CloudOps,Austin,"Looking for DevOps with kubernetes and docker experience.","Kubernetes, docker, aws,ci/cd",2024-05-20
Business Analyst,BizInsights,London,"Analyze business data and build dashboards.","Excel, tableau, sql",2024-04-10
"""

# Save corrected raw data to CSV
data_file_path = 'data/raw/jobs.csv'
df_raw = pd.read_csv(io.StringIO(raw_data_corrected))
df_raw.to_csv(data_file_path, index=False)

print(f"Raw data saved to {data_file_path}")

"""## Run data pipeline

### Subtask:
Execute the `data_pipeline.py` script to process the raw data and generate the necessary files in the `data/processed` directory.

**Reasoning**:
Execute the pipeline function to process the raw data and generate the necessary files.
"""

pipeline(input_dir='data/raw', output_dir='data/processed')

"""## Run model training

### Subtask:
Execute the `train_models.py` script to train the career classifier model using the processed data.

**Reasoning**:
Call the train function from the train_models.py script with the specified data and output directories.

## Create input directory and data file

### Subtask:
Create the `data/raw` directory and save the raw data into a CSV file within this directory.

**Reasoning**:
Create the necessary directories and save the raw data into a CSV file.

**Reasoning**:
The error message "ValueError: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2." indicates that there is at least one class in the target variable `y` that has only a single sample. This is problematic for `train_test_split` with `stratify=y` because it cannot split a class with only one member into both training and testing sets while maintaining the class distribution. To fix this, I will inspect the class distribution of the 'label' column to identify the problematic classes and then either remove those samples or adjust the data or labeling process if possible.
"""

import pandas as pd
import os

data_dir = 'data/processed'
df = pd.read_json(os.path.join(data_dir, 'jobs_processed.json'))

LABEL_KEYWORDS = {
    'Data Scientist': ['data scientist','machine learning','deep learning','nlp','pandas','scikit-learn'],
    'Software Engineer': ['software engineer','backend','java','c++','golang','node.js','api'],
    'DevOps Engineer': ['devops','docker','kubernetes','ci/cd','aws','azure'],
    'Frontend Engineer': ['react','frontend','javascript','css','html'],
    'Product Manager': ['product manager','product owner','roadmap','stakeholder'],
    'Business Analyst': ['business analyst','sql','excel','tableau','power bi']
}

def assign_label(text):
    t = (text or '').lower()
    for label, keys in LABEL_KEYWORDS.items():
        for k in keys:
            if k in t:
                return label
    return 'Other'

df['label'] = df['text_clean'].apply(assign_label)
df = df[df['label'] != 'Other']

print("Class distribution before splitting:")
print(df['label'].value_counts())

"""**Reasoning**:
The class distribution shows that 'Data Scientist', 'DevOps Engineer', and 'Business Analyst' classes each have only one sample. As identified, this is the cause of the `ValueError` when using `stratify=y` in `train_test_split`. With such a small dataset (5 samples total after filtering), stratifying the split is not feasible. To address this, I will remove the `stratify=y` argument from the `train_test_split` call. This will allow the split to proceed, although the class distribution in the train and test sets might not be perfectly balanced. Given the extremely small dataset, a robust model is unlikely, but removing `stratify` will resolve the immediate error and allow the script to run.


"""

import os
import joblib
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report

LABEL_KEYWORDS = {
    'Data Scientist': ['data scientist','machine learning','deep learning','nlp','pandas','scikit-learn'],
    'Software Engineer': ['software engineer','backend','java','c++','golang','node.js','api'],
    'DevOps Engineer': ['devops','docker','kubernetes','ci/cd','aws','azure'],
    'Frontend Engineer': ['react','frontend','javascript','css','html'],
    'Product Manager': ['product manager','product owner','roadmap','stakeholder'],
    'Business Analyst': ['business analyst','sql','excel','tableau','power bi']
}

def assign_label(text):
    t = (text or '').lower()
    for label, keys in LABEL_KEYWORDS.items():
        for k in keys:
            if k in t:
                return label
    return 'Other'

def train(data_dir='data/processed', out_dir='models'):
    df = pd.read_json(os.path.join(data_dir, 'jobs_processed.json'))
    df['label'] = df['text_clean'].apply(assign_label)
    df = df[df['label'] != 'Other']
    if df.empty:
        print('No labeled data found after heuristic labeling. Please provide labeled dataset or expand LABEL_KEYWORDS.')
        return
    X = df['text_clean']
    y = df['label']

    # Removed stratify=y due to small sample size and classes with only one member
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    pipe = Pipeline([
        ('tfidf', TfidfVectorizer(max_features=20000, ngram_range=(1,2))),
        ('clf', RandomForestClassifier(n_estimators=200, random_state=42))
    ])
    pipe.fit(X_train, y_train)
    preds = pipe.predict(X_test)
    print(classification_report(y_test, preds, zero_division=0)) # Added zero_division=0 to handle potential empty classes in test set

    os.makedirs(out_dir, exist_ok=True)
    joblib.dump(pipe, os.path.join(out_dir, 'career_classifier.joblib'))
    print('Saved classifier to', out_dir)

train(data_dir='data/processed', out_dir='models')

"""## Summary:

### Data Analysis Key Findings

*   The initial attempt to read the raw data failed due to unescaped commas within fields, leading to a `ParserError`. This was resolved by quoting fields containing commas in the raw data string.
*   Executing the data pipeline successfully processed the raw data and generated processed data and TF-IDF artifacts in the `data/processed` directory.
*   The model training script initially failed with a `ValueError` during stratified splitting in `train_test_split`. This occurred because some classes in the target variable (derived from heuristic labeling) had only one member, which is incompatible with stratified sampling.
*   Removing the `stratify=y` argument from `train_test_split` resolved the training error, allowing the model to be trained and saved despite the very small dataset size (5 samples) and resulting poor performance.

### Insights or Next Steps

*   The current heuristic labeling and small dataset size result in very few samples per class, making stratified splitting impossible and leading to poor model performance. A larger, professionally labeled dataset is crucial for training a viable career classifier.
*   Consider alternative preprocessing or feature engineering methods if a larger dataset is not immediately available, although data quantity is the primary limitation.

"""